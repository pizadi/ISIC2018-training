{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/pizadi/ISIC2018-training.git\n",
    "from os import chdir\n",
    "chdir('./ISIC2018-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaW-eybQOwEM",
    "outputId": "e1ee3d2b-c633-45b4-9d61-75e21c350aef"
   },
   "outputs": [],
   "source": [
    "!wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Training_Input.zip\n",
    "!wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Training_GroundTruth.zip\n",
    "!wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Validation_Input.zip\n",
    "!wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1_Validation_GroundTruth.zip\n",
    "# !wget https://isic-challenge-data.s3.amazonaws.com/2018/ISIC2018_Task1-2_Test_Input.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhyECTLlO9jC",
    "outputId": "8695217f-7ff6-4d06-addd-6bbd1574156d"
   },
   "outputs": [],
   "source": [
    "!unzip ./ISIC2018_Task1-2_Training_Input.zip\n",
    "!rm ./ISIC2018_Task1-2_Training_Input.zip\n",
    "!unzip ./ISIC2018_Task1_Training_GroundTruth.zip\n",
    "!rm ./ISIC2018_Task1_Training_GroundTruth.zip\n",
    "!unzip ./ISIC2018_Task1-2_Validation_Input.zip\n",
    "!rm ./ISIC2018_Task1-2_Validation_Input.zip\n",
    "!unzip ./ISIC2018_Task1_Validation_GroundTruth.zip\n",
    "!rm ./ISIC2018_Task1_Validation_GroundTruth.zip\n",
    "!mkdir ./Preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQ8w2bznERkO",
    "outputId": "1033eccd-fdce-4672-a780-52259ba7daef"
   },
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Eyx9L39SWZcF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "# import cv2 as cv\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import torchinfo\n",
    "from BaseModel import BaseModel\n",
    "from DoubleUNet import DoubleUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-uIE4qOXmgy",
    "outputId": "1f57c617-868b-4281-c169-740dcd1965f3"
   },
   "outputs": [],
   "source": [
    "TRAIN_INPUT_DIR = './ISIC2018_Task1-2_Training_Input/'\n",
    "TRAIN_GT_DIR = './ISIC2018_Task1_Training_GroundTruth/'\n",
    "\n",
    "VAL_INPUT_DIR = './ISIC2018_Task1-2_Validation_Input/'\n",
    "VAL_GT_DIR = './ISIC2018_Task1_Validation_GroundTruth/'\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 100\n",
    "IM_H, IM_W = 256, 384\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_yhuVfoWgui",
    "outputId": "c2e5facf-f0cf-415c-c5a4-fcabb6421c3e"
   },
   "outputs": [],
   "source": [
    "training_input_files = os.listdir(TRAIN_INPUT_DIR)\n",
    "for filename in training_input_files:\n",
    "  if (filename[-3:] != \"jpg\" and filename[-3:] != \"png\"):\n",
    "    training_input_files.remove(filename)\n",
    "n_train = len(training_input_files)\n",
    "\n",
    "val_input_files = os.listdir(VAL_INPUT_DIR)\n",
    "for filename in val_input_files:\n",
    "  if (filename[-3:] != \"jpg\" and filename[-3:] != \"png\"):\n",
    "    val_input_files.remove(filename)\n",
    "n_val = len(val_input_files)\n",
    "n_train -= n_train % BATCH_SIZE\n",
    "n_val -= n_val % BATCH_SIZE\n",
    "print(n_train, n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jU3o34UPXDZZ",
    "outputId": "e4df1084-279d-4bd9-d472-7209d371ad1e"
   },
   "outputs": [],
   "source": [
    "train_X = torch.zeros((BATCH_SIZE, 3, IM_H, IM_W)).to(DEVICE)\n",
    "train_y = torch.zeros((BATCH_SIZE, 1, IM_H, IM_W)).to(DEVICE)\n",
    "nb = n_train//BATCH_SIZE\n",
    "with tqdm(total=n_train) as pbar:\n",
    "    for f in range(nb):\n",
    "        l, r = f*BATCH_SIZE, (f+1)*BATCH_SIZE\n",
    "        filename = None\n",
    "        for i in range(l, r):\n",
    "            filename = training_input_files[i]\n",
    "            in_image = torchvision.io.read_image(TRAIN_INPUT_DIR + filename).to(DEVICE)\n",
    "            gt_image = torchvision.io.read_image(TRAIN_GT_DIR + filename[:-4] + \"_segmentation.png\").to(DEVICE)\n",
    "            train_X[i-l, :, :, :] = torchvision.transforms.functional.resize(in_image, [IM_H, IM_W])\n",
    "            train_y[i-l, :, :, :] = torchvision.transforms.functional.resize(gt_image, [IM_H, IM_W])\n",
    "            in_image, gt_image = None, None\n",
    "            torch.cuda.empty_cache()\n",
    "            pbar.update(1)\n",
    "\n",
    "        train_y = (train_y//128)\n",
    "        torch.save(train_X, f\"./Preproc/train_X_{f}.torch\")\n",
    "        torch.save(train_y, f\"./Preproc/train_y_{f}.torch\")\n",
    "train_X, train_y = None, None\n",
    "torch.cuda.empty_cache()\n",
    "   \n",
    "val_X = torch.zeros((BATCH_SIZE, 3, IM_H, IM_W)).to(DEVICE)\n",
    "val_y = torch.zeros((BATCH_SIZE, 1, IM_H, IM_W)).to(DEVICE)\n",
    "nb = n_val//BATCH_SIZE\n",
    "with tqdm(total=n_val) as pbar:\n",
    "    for f in range(nb):\n",
    "        l, r = f*BATCH_SIZE, (f+1)*BATCH_SIZE\n",
    "        filename = None\n",
    "        for i in range(l, r):\n",
    "            filename = val_input_files[i]\n",
    "            in_image = torchvision.io.read_image(VAL_INPUT_DIR + filename).to(DEVICE)\n",
    "            gt_image = torchvision.io.read_image(VAL_GT_DIR + filename[:-4] + \"_segmentation.png\").to(DEVICE)\n",
    "            val_X[i-l, :, :, :] = torchvision.transforms.functional.resize(in_image, [IM_H, IM_W])\n",
    "            val_y[i-l, :, :, :] = torchvision.transforms.functional.resize(gt_image, [IM_H, IM_W])\n",
    "            in_image, gt_image = None, None\n",
    "            torch.cuda.empty_cache()\n",
    "            pbar.update(1)\n",
    "\n",
    "        val_y = (val_y//128)\n",
    "        torch.save(val_X, f\"./Preproc/val_X_{f}.torch\")\n",
    "        torch.save(val_y, f\"./Preproc/val_y_{f}.torch\")\n",
    "val_X, val_y = None, None\n",
    "torch.cuda.empty_cache()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-fyJIWGAO24"
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "  num_batches = n_train // BATCH_SIZE\n",
    "  model.train()\n",
    "  t_loss, t_met, proc = 0, torch.tensor([0., 0., 0., 0.]), 0\n",
    "  with tqdm(total=num_batches) as pbar:\n",
    "    pbar.set_description(\"Avg.Loss: 0.0000, Avg. Accuracy: 0.0000\")\n",
    "    for batch in range(num_batches):\n",
    "      X = torch.load(f\"./Preproc/train_X_{batch}.torch\")\n",
    "      y = torch.load(f\"./Preproc/train_y_{batch}.torch\")\n",
    "      loss, met = model.fit(X, y)\n",
    "      t_loss += loss*len(X)\n",
    "      t_met += met\n",
    "      proc += len(X)\n",
    "      pbar.update(1)\n",
    "      pbar.set_description(f\"Avg. Loss: {t_loss/proc: .4f}, Avg. Accuracy: {(t_met[0] + t_met[3])/proc: .4f}\")\n",
    "  return (t_loss/n_train, t_met/n_train)\n",
    "\n",
    "def test(model):\n",
    "  num_batches = n_val // BATCH_SIZE\n",
    "  model.eval()\n",
    "  t_loss, t_met, proc = 0, torch.tensor([0., 0., 0., 0.]), 0\n",
    "  with tqdm(total=num_batches) as pbar:\n",
    "    pbar.set_description(\"Avg.Loss: 0.0000, Avg. Accuracy: 0.0000\")\n",
    "    with torch.no_grad():\n",
    "      for batch in range(num_batches):\n",
    "        X = torch.load(f\"./Preproc/val_X_{batch}.torch\")\n",
    "        y = torch.load(f\"./Preproc/val_y_{batch}.torch\")\n",
    "        loss, met = model.test(X, y)\n",
    "        t_loss += loss*len(X)\n",
    "        t_met += met\n",
    "        proc += len(X)\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(f\"Avg. Loss: {t_loss/proc : .4f}, Avg. Accuracy: {(t_met[0] + t_met[3])/proc: .4f}\")\n",
    "  return (t_loss/n_val, t_met/n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DoubleUNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(EPOCHS):\n",
    "  torch.cuda.empty_cache()\n",
    "  print(f\"Epoch {t+1} ---------------------\")\n",
    "  print(f\"Training Set -----\")\n",
    "  train_loss, _ = train(net)\n",
    "  print(f\"Validation Set -----\")\n",
    "  train_loss, met = test(net)\n",
    "  print(f\"\\rIoU: {met[0] / (met[0] + met[1] + met[2]): .4f}, Dice: {met[0] / (met[0] + 0.5 * (met[1] + met[2])): .4f}, Acc: {met[0] + met[3] : .4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
